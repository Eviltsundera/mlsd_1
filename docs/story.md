# ML System Design - Классификация новостных статей по категориям

## План работы

### 0. Выбор кейса
**Доменная область:** текстовые данные  
**Бизнес-цель:** многоклассовая классификация с похожими классами  
**Задача:** автоматическая классификация новостных статей по категориям (например, Бизнес, Технологии, Спорт, Развлечения, Политика)

### 1. Сбор данных
- **Основные датасеты для рассмотрения:**
  - AG News (4 класса: World, Sports, Business, Sci/Tech)
  - BBC News (5 классов: Business, Entertainment, Politics, Sport, Tech)
  - 20 Newsgroups (20 различных категорий, можно сгруппировать)
  
- **Проверка лицензий:**
  - Проверить возможность использования в обучающих целях
  - Убедиться в отсутствии ограничений для академического использования
  
- **Weak Supervision:**
  - Использовать нелабелированные новостные статьи из других источников
  - Применить zero-shot классификацию через LLM или предобученные модели
  - Создать простые правила на основе ключевых слов для разметки дополнительных данных
  - Опционально: кросс-датасетное обогащение (использовать метки из одного датасета для другого)

### 2. Выбор метрик и разделение данных
- **Метрики:**
  - Основная: Macro F1-score (учитывает все классы равнозначно)
  - Дополнительные: Accuracy, Weighted F1, Confusion Matrix (для анализа ошибок между похожими классами)
  
- **Разделение датасета:**
  - Стратифицированное разделение для сохранения распределения классов
  - Проверка временных эффектов (если есть временные метки)
  - Пропорция: 70% обучающая, 15% валидационная, 15% тестовая

### 3. Подготовка данных
- **Очистка данных:**
  - Удаление дубликатов и проверка на near-duplicates
  - Обработка пропусков (если имеются)
  - Проверка на аномально короткие/длинные тексты
  
- **Предобработка текста:**
  - Приведение к нижнему регистру
  - Удаление/замена HTML-тегов, спецсимволов
  - Токенизация с учетом особенностей трансформеров
  - Анализ распределения длин текстов и выбор стратегии обрезания/дополнения
  
- **Аугментации:**
  - Синонимическая замена слов
  - Back-translation (перевод на другой язык и обратно)
  - Удаление случайных слов или фраз
  - Добавление шума (опечатки, перестановки)
  
- **Проверка на утечку:**
  - Поиск пересечений между train и test
  - Анализ источников данных на возможные утечки
  - Проверка временных границ (если применимо)

### 4. Бейзлайн
- **Простые модели для бейзлайна:**
  - TF-IDF + LogisticRegression (многоклассовая)
  - TF-IDF + SVM с линейным ядром
  - Fasttext с предобученными векторами
  
- **Оценка и анализ бейзлайна:**
  - Замер метрик на валидационной выборке
  - Анализ ошибок (особое внимание к похожим классам)
  - Создание confusion matrix для визуализации проблемных зон

### 5. Обучение первой DL модели
- **Выбор архитектуры:**
  - Легкий трансформер: DistilBERT, MobileBERT или TinyBERT
  - Стратегии для экономии ресурсов:
    - Замораживание embedding слоев
    - Постепенная разморозка слоев (progressive unfreezing)
    - Низкоранговая адаптация (LoRA)
  
- **Трекинг экспериментов:**
  - Настройка Weights & Biases (W&B) или MLflow
  - Отслеживание:
    - Loss на train/val
    - Метрики (F1-macro, accuracy) на train/val
    - Confusion matrix
    - Примеры ошибок классификации
    - Время обучения и использование памяти

### 6. Дальнейшие шаги (опционально)
- Гиперпараметрическая оптимизация (learning rate, batch size, длина последовательности)
- Ансамблирование с бейзлайн-методами
- Анализ ошибок и целевая доработка для проблемных классов
- Интерпретация модели (SHAP, LIME, attention weights)

## Текущий прогресс
*(Здесь будет обновляться статус выполнения каждого этапа)*

### Выбор кейса: ✅
- Выбрана задача многоклассовой классификации новостных текстов

### Сбор данных: ⏳
## Текущий прогресс

### Настройка проекта: ✅ (17.03.2024)
- Создана структура проекта с модулями для обработки данных и моделей
- Настроены окружения для Conda и Pip
- Реализована базовая интеграция с Kaggle API

### Сбор данных: ✅ (17.03.2024)
**Загружены датасеты:**
1. **AG News** (120k статей)
   - Источник: Hugging Face Datasets
   - Лицензия: CC BY-SA 3.0
   - Автоматическое разделение на train/test
   - Сохранен в формате `datasets.DatasetDict`

2. **BBC News** (2,225 статей)
   - Источник: Kaggle
   - Особенности:
     - Ручная загрузка через Kaggle API
     - Преобразование CSV в DatasetDict
     - Стратифицированное разделение 80/20

3. **20 Newsgroups** (18k документов)
   - Источник: scikit-learn
   - Особенности обработки:
     - Удаление headers/footers
     - Сохранение оригинальных 20 классов
     - Стратифицированное разделение

**Проверка лицензий:**
- Все датасеты разрешены для академического использования
- BBC News требует указания источника при публикации

### Анализ данных: ✅ (17.03.2024)
**Результаты анализа датасетов:**

1. **AG News** (127,600 статей):
   - Распределение по классам: равномерное (по 25% на каждый класс)
   - Статистика текстов:
     - Средняя длина: ~40 слов
     - Короткие новостные заголовки и краткие описания
   - Качество данных:
     - Нет дубликатов в обучающей и тестовой выборках
     - Нет пересечений между обучающей и тестовой выборками
     - Данные хорошо подготовлены и очищены

2. **BBC News** (2,225 статей):
   - Распределение по классам: неравномерное
     - business: ~20%
     - entertainment: ~17%
     - politics: ~23%
     - sport: ~22%
     - tech: ~18%
   - Статистика текстов:
     - Средняя длина: ~400 слов
     - Полные тексты новостных статей
   - Проблемы качества:
     - 82 дубликата в обучающей выборке (из 1,780 текстов)
     - 5 дубликатов в тестовой выборке (из 445 текстов)
     - 46 пересечений между обучающей и тестовой выборками

3. **20 Newsgroups** (18,846 документов):
   - Распределение по классам: относительно равномерное (20 классов)
   - Статистика текстов:
     - Средняя длина: ~300 слов
     - Тексты из новостных групп, включая обсуждения
   - Проблемы качества:
     - 320 дубликатов в обучающей выборке (из 11,314 текстов)
     - 221 дубликат в тестовой выборке (из 7,532 текстов)
     - 18 пересечений между обучающей и тестовой выборками

**Пересечения между датасетами:**
- Не обнаружено пересечений между разными датасетами
- Каждый датасет содержит уникальные тексты

**Выводы и рекомендации:**
1. **Предобработка данных:**
   - Удалить дубликаты в BBC News и 20 Newsgroups
   - Исключить пересечения между train/test в BBC News и 20 Newsgroups
   - Нормализовать длину текстов (особенно для BBC News с длинными статьями)

2. **Стратегия обучения:**
   - Использовать AG News как основной датасет для первичного обучения (чистые данные)
   - Применить transfer learning на BBC News и 20 Newsgroups
   - Учитывать дисбаланс классов при обучении на BBC News

3. **Особенности датасетов:**
   - AG News: короткие тексты, подходит для быстрого обучения и экспериментов
   - BBC News: длинные статьи, потребуется стратегия обработки длинных текстов
   - 20 Newsgroups: разнообразные темы, хорошо подходит для оценки обобщающей способности

### Следующие шаги:
1. Реализация предобработки текстов с учетом выявленных проблем
2. Создание единого пайплайна для работы со всеми тремя датасетами
3. Разработка бейзлайн-моделей для сравнения 

### Объединение датасетов: ✅ (17.03.2024)
**Подход к гармонизации меток:**

Для объединения трех датасетов с разными системами меток была разработана система гармонизации с 6 общими категориями:
- `world`: новости о мире, политике (World из AG News, Politics из BBC News, политические темы из 20 Newsgroups)
- `business`: бизнес-новости (Business из AG News и BBC News, misc.forsale из 20 Newsgroups)
- `sports`: спортивные новости (Sports из AG News, Sport из BBC News, спортивные темы из 20 Newsgroups)
- `technology`: технологические новости (Sci/Tech из AG News, Tech из BBC News, компьютерные и научные темы из 20 Newsgroups)
- `entertainment`: развлечения (Entertainment из BBC News)
- `other`: прочие темы (религия, автомобили и другие темы из 20 Newsgroups)

**Процесс объединения:**
1. Загрузка очищенных датасетов (без дубликатов и пересечений)
2. Добавление новой колонки `harmonized_label` с гармонизированными метками
3. Добавление колонки `source` для отслеживания источника каждого примера
4. Объединение датасетов с сохранением разделения на train/test
5. Сохранение объединенного датасета

**Статистика объединенного датасета:**
- Общее количество примеров: 147,673
- Распределение по источникам:
  - AG News: 127,355 примеров (86.2%)
  - BBC News: 2,086 примеров (1.4%)
  - 20 Newsgroups: 18,232 примеров (12.4%)

**Результаты анализа объединенного датасета:**

1. **Распределение классов (6 классов):**
   - **Обучающая выборка:**
     - technology: 34,749 (26.2%)
     - world: 31,820 (24.0%)
     - sports: 31,515 (23.8%)
     - business: 30,913 (23.3%)
     - other: 3,133 (2.4%)
     - entertainment: 296 (0.2%)
   - **Тестовая выборка:**
     - technology: 4,976 (32.6%)
     - world: 2,999 (19.7%)
     - sports: 2,764 (18.1%)
     - business: 2,364 (15.5%)
     - other: 2,074 (13.6%)
     - entertainment: 70 (0.5%)

2. **Статистика длины текстов:**
   - **Общая статистика:**
     - Минимум: 1 слово
     - Максимум: 11,765 слов
     - Среднее: 54.9 слов
     - Медиана: 38 слов
   - **По источникам:**
     - AG News: среднее 37.8 слов, медиана 37 слов
     - BBC News: среднее 375.8 слов, медиана 321 слово
     - 20 Newsgroups: среднее 191.4 слов, медиана 86 слов

3. **Распределение источников:**
   - **Обучающая выборка:**
     - AG News: 119,773 (90.4%)
     - 20 Newsgroups: 10,958 (8.3%)
     - BBC News: 1,695 (1.3%)
   - **Тестовая выборка:**
     - AG News: 7,582 (49.7%)
     - 20 Newsgroups: 7,274 (47.7%)
     - BBC News: 391 (2.6%)

**Выводы и рекомендации:**
1. **Дисбаланс классов:**
   - Наблюдается значительный дисбаланс: классы "other" и "entertainment" представлены очень малым количеством примеров.
   - Рекомендуется использовать стратегии для работы с несбалансированными классами, такие как взвешивание классов или техники аугментации данных.

2. **Различия в длине текстов:**
   - Тексты из BBC News значительно длиннее (в среднем 375.8 слов), чем из AG News (37.8 слов).
   - Необходима стратегия обработки текстов разной длины: усечение длинных текстов или использование иерархических моделей.

3. **Дисбаланс источников:**
   - Большинство примеров (86.2%) приходится на AG News, что может привести к смещению модели в сторону этого источника.
   - Рекомендуется использовать стратегии балансировки или взвешивания примеров при обучении.

4. **Различия между обучающей и тестовой выборками:**
   - В тестовой выборке доля 20 Newsgroups значительно выше (47.7% против 8.3% в обучающей), что может повлиять на оценку качества модели.
   - Рекомендуется создать дополнительную валидационную выборку с распределением, близким к тестовой.

**Преимущества подхода:**
1. Сохранение оригинальных меток для возможности обучения на отдельных датасетах
2. Добавление гармонизированных меток для обучения на объединенном датасете
3. Возможность анализа влияния источника данных на качество классификации

### Следующие шаги:
1. Реализация предобработки текстов для объединенного датасета
2. Разработка бейзлайн-моделей на основе TF-IDF и классических алгоритмов
3. Обучение трансформеров на объединенном датасете 

## Проект по классификации новостных статей

### Цель проекта
Разработать систему классификации новостных статей с использованием современных методов обработки естественного языка.

### Используемые датасеты
1. **AG News** - коллекция новостных статей, собранных из более чем 2000 источников новостей.
   - 4 класса: World, Sports, Business, Sci/Tech
   - Около 120,000 обучающих примеров и 7,600 тестовых примеров

2. **BBC News** - коллекция новостных статей от BBC.
   - 5 классов: Business, Entertainment, Politics, Sport, Tech
   - Около 2,225 примеров

3. **20 Newsgroups** - коллекция новостных сообщений из 20 различных групп новостей.
   - 20 классов, сгруппированных по темам
   - Около 18,000 примеров

### Текущий прогресс

#### Анализ датасетов
Проведен анализ трех датасетов: AG News, BBC News и 20 Newsgroups. Выявлены следующие особенности:

1. **Распределение классов**:
   - AG News: равномерное распределение между 4 классами
   - BBC News: неравномерное распределение, с преобладанием класса "business"
   - 20 Newsgroups: относительно равномерное распределение между 20 классами

2. **Длина текстов**:
   - AG News: короткие тексты (заголовки и краткое описание)
   - BBC News: длинные тексты (полные статьи)
   - 20 Newsgroups: тексты средней длины (сообщения из групп новостей)

3. **Проблемы в данных**:
   - Обнаружены дубликаты в обучающей и тестовой выборках
   - Найдены пересечения между обучающей и тестовой выборками
   - В BBC News некоторые тексты отсутствуют (None)

#### Очистка данных
Разработан скрипт для очистки данных, который:
1. Удаляет дубликаты в обучающей и тестовой выборках
2. Удаляет пересечения между обучающей и тестовой выборками
3. Сохраняет очищенные данные

Результаты очистки:
- AG News: удалено небольшое количество дубликатов
- BBC News: удалено несколько дубликатов и пересечений
- 20 Newsgroups: удалено значительное количество дубликатов и пересечений

#### Объединение датасетов
Разработан подход к объединению трех датасетов с гармонизацией меток классов:

1. **Гармонизация меток**:
   Создана единая система меток для всех трех датасетов:
   - `world`: новости о мировых событиях, политике
   - `business`: бизнес, экономика, финансы
   - `sports`: спорт
   - `technology`: технологии, наука
   - `entertainment`: развлечения, искусство
   - `other`: прочие темы, не входящие в основные категории

2. **Процесс объединения**:
   - Загрузка очищенных датасетов
   - Добавление гармонизированных меток
   - Сохранение информации об источнике данных
   - Создание трех выборок: обучающей, валидационной и тестовой
   - Сохранение объединенного датасета

3. **Статистика объединенного датасета**:
   - Общее количество примеров: ~148,000
   - Распределение по источникам: 
     - AG News: ~85%
     - BBC News: ~1.5%
     - 20 Newsgroups: ~13.5%
   - Распределение по выборкам:
     - Обучающая: 70%
     - Валидационная: 15%
     - Тестовая: 15%

4. **Преимущества подхода**:
   - Сохранение оригинальных меток
   - Добавление гармонизированных меток для обучения
   - Возможность анализа влияния источника данных на качество классификации
   - Стратифицированное разделение на выборки с учетом классов и источников

#### Анализ объединенного датасета
Проведен анализ объединенного датасета, который показал:

1. **Распределение классов**:
   - Обучающая выборка:
     - technology: 26.2%
     - world: 24.0%
     - sports: 23.8%
     - business: 23.3%
     - other: 2.4%
     - entertainment: 0.2%
   - Валидационная выборка: аналогичное распределение
   - Тестовая выборка: аналогичное распределение

2. **Длина текстов**:
   - Значительные различия в длине текстов между источниками
   - Средняя длина текста: ~200 слов
   - Медианная длина текста: ~100 слов
   - Максимальная длина текста: >10,000 слов

3. **Распределение источников**:
   - Все выборки имеют схожее распределение источников
   - Стратификация по источникам и классам обеспечивает репрезентативность выборок

### Следующие шаги
1. Реализация предобработки текстов с учетом выявленных особенностей:
   - Токенизация
   - Нормализация длины текстов
   - Обработка специальных символов

2. Разработка базовых моделей для сравнения:
   - TF-IDF + Logistic Regression
   - TF-IDF + SVM

3. Обучение трансформеров для классификации новостей:
   - BERT
   - RoBERTa
   - DistilBERT 