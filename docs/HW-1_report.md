# Отчёт по Домашнему заданию 1, ML System Design

**Студент:** Гайнанов Даниль Эльдарович

**Кейс:** Классификация новостных статей по категориям

**Тип данных:** Тексты новостных статей

**Бизнес-цель:** Многоклассовая классификация текстов

---

### **1. Данные**

**Источник данных:** 
- AG News (Hugging Face Datasets)
- BBC News (Kaggle)
- 20 Newsgroups (scikit-learn)

**Лицензия:** ✔ Да
- AG News: CC BY-SA 3.0
- BBC News: CC BY-NC-SA 4.0
- 20 Newsgroups: BSD 3-Clause

**Weak Supervision:** Использовался
- **Self-training:**
  - Использование предварительно обученного BERT для разметки спорных случаев
  - Итеративное улучшение качества разметки
  - Порог уверенности 0.95 для добавления новых примеров
  - Проверка согласованности с оригинальными метками

**Объем данных:**
- **Train:** 125,622 записей
- **Validation:** 19,851 записей
- **Test:** 2,200 записей

---

### **2. Метрики и разбиение данных**

**Основная метрика:** Accuracy

**Дополнительные метрики:** 
- F1-score (по классам)
- Confusion Matrix

**Способ разбиения:** Стратифицированное (по классам и источникам)

---

### **3. Обработка данных**

✔ Дубликаты удалены: Да
- Удалены дубликаты внутри датасетов
- Устранены пересечения между train/test

✔ Пропуски обработаны: Да
- Проверены и обработаны пропущенные значения в BBC News
- Корректно обработаны поля text/content

✔ Аугментации / Feature Engineering: 
- **Текстовая предобработка:**
  - Удаление HTML-тегов и специальных символов
  - Приведение к нижнему регистру
  - Удаление пунктуации
  - Лемматизация (spaCy)
  - Удаление стоп-слов
- **Аугментации текста:**
  - Back-translation (английский -> немецкий -> английский)
  - Синонимизация (WordNet)
  - Замена случайных слов на их синонимы
  - Удаление случайных слов (10% текста)
  - Перестановка предложений
- **Feature Engineering:**
  - TF-IDF векторизация
  - Длина текста
  - Количество предложений
  - Средняя длина предложения
  - Количество уникальных слов
  - Соотношение уникальных/общих слов
- **Гармонизация меток:**
  - 6 общих классов
  - Сохранение информации об источниках
  - Сохранение оригинальных меток для анализа

✔ Проверка на утечки: 
- Проверено отсутствие пересечений между train/test
- Проверено отсутствие утечек из источников
- Сохранена информация об источниках для анализа

---

### **4. Бейзлайн**

**Выбранный бейзлайн:** 
- TF-IDF + Logistic Regression
  - Векторизация: TF-IDF с биграммами (max_features=10000)
  - Модель: LogisticRegression с multinomial классификацией
  - Сбалансированные веса классов
  - Максимум 1000 итераций

**Качество бейзлайна:** 
- Валидационная accuracy: 0.8797
- Валидационный F1-score: 0.8854
- Тестовая accuracy: 0.7864
- Тестовый F1-score: 0.8018

**Дополнительные метрики:**
- Confusion Matrix
- Classification Report
- Важность признаков

**Результаты сохранены в:**
- models/baseline/baseline_results.json
- models/baseline/confusion_matrix.png
- models/baseline/baseline_model.joblib
- models/baseline/tfidf_vectorizer.joblib

**Анализ результатов:**
- Хорошая производительность на валидационной выборке (>87%)
- Небольшое падение на тестовой выборке (~7%)
- Сбалансированная производительность по классам (F1-score > 0.80)
- Возможность улучшения через:
  - Увеличение размера обучающей выборки
  - Использование более сложных моделей (BERT)
  - Дополнительная предобработка текста

---

**Примечание:** Реализован полный пайплайн обработки данных с учетом лицензий и требований к качеству данных.

### **5. BERT модель**

#### Архитектура
- Модель: DistilBERT-base-uncased (66M параметров)
- Максимальная длина текста: 128 токенов
- Размер батча: 32 (эффективный 128 с градиентным накоплением)
- Learning rate: 2e-5
- Количество эпох: 3

#### Оптимизация
- Градиентное накопление: 4 шага
- Линейный разогрев learning rate
- Weight decay: 0.01
- Сбалансированные веса классов

#### Отслеживание экспериментов
- Использование Weights & Biases (wandb)
- Метрики: loss, accuracy, F1-score, learning rate

#### Результаты
- Валидационная accuracy: 0.9282
- Валидационный F1-score: 0.9273
- Тестовая accuracy: 0.8863
- Тестовый F1-score: 0.8863

Модель показала отличные результаты на валидационной выборке, достигнув accuracy 92.82% и F1-score 92.73%. На тестовой выборке результаты немного ниже (88.63%), что может указывать на небольшой переобучении. Тем не менее, результаты значительно превосходят базовую модель TF-IDF + Logistic Regression.

#### Результаты сохранены в:
- `models/bert/best_model/` - лучшая модель
- `models/bert/bert_results.json` - метрики и отчет о классификации
- `wandb/` - логи и метрики обучения