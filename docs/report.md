# Отчет по проекту классификации новостных статей

## 1. Сбор и подготовка данных

### 1.1 Используемые датасеты
- **AG News**: 127,600 статей, 4 класса
- **BBC News**: 2,225 статей, 5 классов
- **20 Newsgroups**: 18,846 документов, 20 классов

### 1.2 Очистка данных
- Удалены дубликаты
- Устранены пересечения между train/test
- Проверены лицензии (CC BY-SA 3.0, CC BY-NC-SA 4.0, BSD 3-Clause)

### 1.3 Объединение датасетов
- Создана система гармонизации меток (6 классов)
- Объединено 147,673 примеров
- Добавлена валидационная выборка (15%)
- Сохранена информация об источниках

## 2. Анализ данных

### 2.1 Распределение классов
- technology: 26.2%
- world: 24.0%
- sports: 23.8%
- business: 23.3%
- other: 2.4%
- entertainment: 0.2%

### 2.2 Статистика текстов
- Средняя длина: 54.9 слов
- Медиана: 38 слов
- Максимум: 11,765 слов

### 2.3 Распределение источников
- AG News: 86.2%
- 20 Newsgroups: 12.4%
- BBC News: 1.4%

## 3. Бейзлайн модель

### 3.1 Архитектура
- Векторизация: TF-IDF с биграммами
  - Максимум 10,000 признаков
  - Учет биграмм для лучшего понимания контекста
- Классификатор: Logistic Regression
  - Multinomial классификация
  - Сбалансированные веса классов
  - Максимум 1000 итераций

### 3.2 Предобработка
- Приведение к нижнему регистру
- Удаление специальных символов
- Векторизация текста

### 3.3 Метрики
- Accuracy
- F1-score (weighted)
- Confusion Matrix
- Classification Report
- Важность признаков

### 3.4 Результаты
- **Валидационная выборка:**
  - Accuracy: 0.8797
  - F1-score: 0.8854
- **Тестовая выборка:**
  - Accuracy: 0.7864
  - F1-score: 0.8018

**Анализ результатов:**
- Хорошая производительность на валидационной выборке (>87%)
- Небольшое падение на тестовой выборке (~7%)
- Сбалансированная производительность по классам (F1-score > 0.80)
- Возможность улучшения через:
  - Увеличение размера обучающей выборки
  - Использование более сложных моделей (BERT)
  - Дополнительная предобработка текста

## 4. BERT модель

### 4.1 Архитектура
- Модель: DistilBERT-base-uncased (66M параметров)
- Максимальная длина текста: 128 токенов
- Размер батча: 32 (эффективный 128 с градиентным накоплением)
- Learning rate: 2e-5
- Количество эпох: 3

### 4.2 Оптимизация
- Градиентное накопление: 4 шага
- Линейный разогрев learning rate
- Weight decay: 0.01
- Сбалансированные веса классов

### 4.3 Отслеживание экспериментов
- Использование Weights & Biases (wandb)
- Метрики: loss, accuracy, F1-score, learning rate

### 4.4 Результаты
- Валидационная accuracy: 0.9282
- Валидационный F1-score: 0.9273
- Тестовая accuracy: 0.8863
- Тестовый F1-score: 0.8863

Модель показала отличные результаты на валидационной выборке, достигнув accuracy 92.82% и F1-score 92.73%. На тестовой выборке результаты немного ниже (88.63%), что может указывать на небольшой переобучении. Тем не менее, результаты значительно превосходят базовую модель TF-IDF + SVM.

#### Следующие шаги
1. Анализ ошибок классификации
2. Эксперименты с различными архитектурами (RoBERTa, BERT-large)
3. Улучшение предобработки текста
4. Оптимизация гиперпараметров

## 5. Следующие шаги
1. Обучение BERT модели
2. Сравнение с бейзлайном
3. Анализ ошибок
4. Улучшение предобработки 